{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Semantic Segmentation\n",
    "\n",
    "This notebook demonstrates the implementation and usage of U-Net for semantic segmentation with GPU support.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Requirements\n",
    "2. U-Net Model Implementation\n",
    "3. Data Loading and Preprocessing\n",
    "4. Model Training\n",
    "5. Inference and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Requirements\n",
    "\n",
    "First, let's install the required packages and check GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install tensorflow-gpu numpy opencv-python pillow matplotlib pandas tqdm pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU(s) available and configured: {[gpu.name for gpu in physical_devices]}\")\n",
    "        # Enable mixed precision\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        print(\"Mixed precision training enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. U-Net Model Implementation\n",
    "\n",
    "Let's implement the U-Net architecture with GPU optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class UNet:\n",
    "    def __init__(self, input_size=None, n_classes=1):\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def conv_block(self, inputs, filters):\n",
    "        \"\"\"Convolutional block with two conv layers\"\"\"\n",
    "        conv = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding='same')(inputs)\n",
    "        conv = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding='same')(conv)\n",
    "        return conv\n",
    "    \n",
    "    def upconv_block(self, inputs, skip_connection, filters):\n",
    "        \"\"\"Upsampling block with skip connection\"\"\"\n",
    "        up = tf.keras.layers.UpSampling2D(size=(2, 2))(inputs)\n",
    "        up = tf.keras.layers.Conv2D(filters, 2, activation='relu', padding='same')(up)\n",
    "        concat = tf.keras.layers.Concatenate()([up, skip_connection])\n",
    "        conv = self.conv_block(concat, filters)\n",
    "        return conv\n",
    "        \n",
    "    def build_model(self):\n",
    "        # Set compute dtype for better GPU performance\n",
    "        compute_dtype = tf.float16 if len(tf.config.list_physical_devices('GPU')) > 0 else tf.float32\n",
    "        \n",
    "        # Input layer\n",
    "        if self.input_size is None:\n",
    "            inputs = tf.keras.layers.Input(shape=(None, None, 3))\n",
    "        else:\n",
    "            inputs = tf.keras.layers.Input(shape=self.input_size)\n",
    "            \n",
    "        # Cast input to float16 for GPU optimization\n",
    "        if compute_dtype == tf.float16:\n",
    "            inputs = tf.keras.layers.Cast(dtype=tf.float16)(inputs)\n",
    "        \n",
    "        # Encoder\n",
    "        conv1 = self.conv_block(inputs, 64)\n",
    "        pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        \n",
    "        conv2 = self.conv_block(pool1, 128)\n",
    "        pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        \n",
    "        conv3 = self.conv_block(pool2, 256)\n",
    "        pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        \n",
    "        conv4 = self.conv_block(pool3, 512)\n",
    "        pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        \n",
    "        # Bridge\n",
    "        conv5 = self.conv_block(pool4, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        up6 = self.upconv_block(conv5, conv4, 512)\n",
    "        up7 = self.upconv_block(up6, conv3, 256)\n",
    "        up8 = self.upconv_block(up7, conv2, 128)\n",
    "        up9 = self.upconv_block(up8, conv1, 64)\n",
    "        \n",
    "        # Cast back to float32 for output\n",
    "        if compute_dtype == tf.float16:\n",
    "            up9 = tf.keras.layers.Cast(dtype=tf.float32)(up9)\n",
    "        \n",
    "        # Output\n",
    "        outputs = tf.keras.layers.Conv2D(self.n_classes, 1, activation='sigmoid')(up9)\n",
    "        \n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, model, learning_rate=1e-4):\n",
    "        # Use AMP optimizer if GPU is available\n",
    "        if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "        else:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)]\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing\n",
    "\n",
    "Let's implement data loading and preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "def load_coco_dataset(images_dir, annotations_file):\n",
    "    \"\"\"Load and preprocess COCO dataset\"\"\"\n",
    "    coco = COCO(annotations_file)\n",
    "    \n",
    "    # Get all image IDs\n",
    "    image_ids = coco.getImgIds()\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for img_id in tqdm(image_ids, desc=\"Loading dataset\"):\n",
    "        # Load image info\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        image_path = os.path.join(images_dir, img_info['file_name'])\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get annotations\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        \n",
    "        # Create mask\n",
    "        mask = np.zeros((img_info['height'], img_info['width']))\n",
    "        for ann in anns:\n",
    "            mask = np.maximum(mask, coco.annToMask(ann))\n",
    "            \n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "        image_paths.append(image_path)\n",
    "        \n",
    "    return np.array(images), np.array(masks), image_paths\n",
    "\n",
    "def prepare_dataset(images, masks, batch_size=4):\n",
    "    \"\"\"Prepare dataset with GPU optimization\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
    "    \n",
    "    # Optimize dataset for GPU training\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Now let's train the model with GPU optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "images_dir = 'data/images'\n",
    "annotations_file = 'data/annotations/instances.json'\n",
    "\n",
    "images, masks, image_paths = load_coco_dataset(images_dir, annotations_file)\n",
    "dataset = prepare_dataset(images, masks, batch_size=4)\n",
    "\n",
    "# Create and compile model\n",
    "unet = UNet()\n",
    "model = unet.build_model()\n",
    "model = unet.compile_model(model)\n",
    "\n",
    "# Training callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'weights/unet_best.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs',\n",
    "        histogram_freq=1,\n",
    "        profile_batch='500,520'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Visualization\n",
    "\n",
    "Let's create functions to perform inference and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess image for inference\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def predict_mask(model, image):\n",
    "    \"\"\"Predict segmentation mask\"\"\"\n",
    "    # Add batch dimension\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(image_batch)\n",
    "    mask = prediction[0] > 0.5\n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "def visualize_results(image, mask):\n",
    "    \"\"\"Visualize original image, mask and overlay\"\"\"\n",
    "    # Create colored mask\n",
    "    mask_colored = cv2.applyColorMap((mask * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    mask_colored = cv2.cvtColor(mask_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create overlay\n",
    "    overlay = cv2.addWeighted(image, 0.7, mask_colored, 0.3, 0)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.title('Segmentation Mask')\n",
    "    plt.imshow(mask, cmap='jet')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.title('Overlay')\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Perform inference on a test image\n",
    "test_image_path = 'path/to/test/image.jpg'\n",
    "image = load_and_preprocess_image(test_image_path)\n",
    "mask = predict_mask(model, image)\n",
    "visualize_results(image, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
